{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "numKxJiXEuqN",
        "outputId": "75c4803b-7836-4207-cc42-caeddc2225fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import yfinance as yf\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, Bidirectional,Conv1D, MaxPooling1D, Flatten,SimpleRNN,GRU\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "lstm_predictions = []\n",
        "bilstm_predictions = []\n",
        "cnn_predictions = []\n",
        "rnn_predictions = []\n",
        "gru_predictions = []\n",
        "xgb_predictions = []\n",
        "\n",
        "sc = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "\n",
        "\n",
        "def get_stock_data(ticker, start_date, end_date):\n",
        "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
        "    return stock_data\n",
        "\n",
        "\n",
        "def prepare_data(dataset_train):\n",
        "    # Verileri ölçeklendirme\n",
        "    training_set_scaled = sc.fit_transform(dataset_train.iloc[:, 4:5].values)\n",
        "    # Veri yapısını oluşturma\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    for i in range(60, len(training_set_scaled)):\n",
        "        X_train.append(training_set_scaled[i-60:i, 0])\n",
        "        y_train.append(training_set_scaled[i, 0])\n",
        "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "\n",
        "    # Yeniden şekillendirme\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "\n",
        "    return X_train, y_train\n",
        "\n",
        "\n",
        "st.title('Borsa Kapanış Fiyatı Tahmini')\n",
        "\n",
        "# Data Preprocessing\n",
        "st.header('Veri Ön İşleme')\n",
        "\n",
        "# Define ticker symbol and date range\n",
        "ticker_symbol = st.selectbox(\"Hisse Sembolünü Seçiniz.\", [\"AMZN\", \"AAPL\", \"GOOGL\", \"MSFT\"])\n",
        "start_date = st.date_input(\"Başlangıç Tarihi\", value=pd.to_datetime('2020-01-01'))\n",
        "end_date = st.date_input(\"Bitiş Tarihi\", value=pd.to_datetime('2024-01-01'))\n",
        "\n",
        "# Slider for selecting percentage of data for training set\n",
        "train_percentage = st.slider(\"Eğitim İçin Yüzde Ayarlayın\", 20, 100, 80)\n",
        "\n",
        "epoch = st.number_input(\"Epoch\", min_value=0)\n",
        "\n",
        "cboxLSTM = st.checkbox('LSTM')\n",
        "cboxBILSTM = st.checkbox('BILSTM')\n",
        "# cboxARIMA = st.checkbox('ARIMA')\n",
        "cboxCNN = st.checkbox('CNN')\n",
        "cboxRNN = st.checkbox('RNN')\n",
        "cboxGRU = st.checkbox('GRU')\n",
        "cboxXGB = st.checkbox('XGBoost')\n",
        "\n",
        "# Load stock data when button is clicked\n",
        "if st.button(\"Verileri Al ve Eğitmeye Başla\"):\n",
        "    stock_data = get_stock_data(ticker_symbol, start_date, end_date)\n",
        "    st.subheader('Borsa Verileri')\n",
        "    st.write(stock_data)\n",
        "\n",
        "    # Calculate number of rows for training set based on selected percentage\n",
        "    total_rows = len(stock_data)\n",
        "    train_rows = int(total_rows * train_percentage / 100)\n",
        "\n",
        "    # Create training and test data sets\n",
        "    training_data = stock_data.head(train_rows)\n",
        "    test_data = stock_data.tail(total_rows - train_rows)\n",
        "\n",
        "    st.subheader('Eğitim Veriseti - Borsa Verisi')\n",
        "    st.write(training_data)\n",
        "\n",
        "    st.subheader('Test Veriseti - Borsa Verisi')\n",
        "    st.write(test_data)\n",
        "\n",
        "    test_data.reset_index(inplace=True)\n",
        "\n",
        "    date_df = pd.DataFrame(test_data.iloc[:, 0].values, columns=['Date'])\n",
        "\n",
        "\n",
        "    # Load dataset_train globally\n",
        "    dataset_train = training_data\n",
        "\n",
        "    # Fitting the LSTM to the Training set\n",
        "    with st.spinner('Model eğitiliyor...'):\n",
        "        # Making predictions\n",
        "        st.header('Tahmin Yapılıyor')\n",
        "        if cboxLSTM :\n",
        "           # Initialising the LSTM\n",
        "          with st.spinner('LSTM modeli eğitiliyor...'):\n",
        "            X_train_lstm, y_train_lstm = prepare_data(dataset_train)\n",
        "            regressorLSTM = Sequential()\n",
        "\n",
        "            # Adding the LSTM layers with Dropout regularisation\n",
        "            regressorLSTM.add(LSTM(units=50, return_sequences=True, input_shape=(X_train_lstm.shape[1], 1)))\n",
        "            regressorLSTM.add(Dropout(0.2))\n",
        "\n",
        "            regressorLSTM.add(LSTM(units=50, return_sequences=True))\n",
        "            regressorLSTM.add(Dropout(0.2))\n",
        "\n",
        "            regressorLSTM.add(LSTM(units=50, return_sequences=True))\n",
        "            regressorLSTM.add(Dropout(0.2))\n",
        "\n",
        "            regressorLSTM.add(LSTM(units=50))\n",
        "            regressorLSTM.add(Dropout(0.2))\n",
        "\n",
        "            # Adding the output layer\n",
        "            regressorLSTM.add(Dense(units=1))\n",
        "\n",
        "            # Compiling the RNN\n",
        "            regressorLSTM.compile(optimizer='adam', loss='mean_squared_error')\n",
        "            regressorLSTM.fit(X_train_lstm, y_train_lstm, epochs=epoch, batch_size=32)\n",
        "\n",
        "            # Getting the real stock price of 2017\n",
        "            dataset_test = test_data\n",
        "            real_stock_price = dataset_test.iloc[:, 4:5].values\n",
        "\n",
        "            # Getting the predicted stock price of 2017\n",
        "            dataset_total = pd.concat((dataset_train['Close'], dataset_test['Close']), axis=0)\n",
        "            inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
        "            inputs = inputs.reshape(-1, 1)\n",
        "            inputs = sc.transform(inputs)\n",
        "            X_test = []\n",
        "            for i in range(60, len(inputs)):\n",
        "                X_test.append(inputs[i-60:i, 0])\n",
        "            X_test = np.array(X_test)\n",
        "            X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "            predicted_stock_price_lstm = regressorLSTM.predict(X_test)\n",
        "            predicted_stock_price_lstm = sc.inverse_transform(predicted_stock_price_lstm)\n",
        "\n",
        "            st.header('LSTM Sonuçları')\n",
        "            plt.plot(real_stock_price, color='red', label='Gerçek '+ ticker_symbol +' Kapanış Fiyatları')\n",
        "            plt.plot(predicted_stock_price_lstm, color='blue', label='Tahmin Edilen '+ ticker_symbol +' Kapanış Fiyatları')\n",
        "            plt.title('LSTM Model Tahminleri')\n",
        "            plt.xlabel('Zaman')\n",
        "            plt.ylabel('Kapanış Fiyatı')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "            st.pyplot(plt)\n",
        "            df_lstm = pd.DataFrame(predicted_stock_price_lstm, columns=['Tahmin Edilen LSTM Sonuçları'])\n",
        "            lstm_predictions = predicted_stock_price_lstm.flatten()\n",
        "            st.header('Tahmin Edilen ' + ticker_symbol + ' Hissesi Fiyatları LSTM - Tablo')\n",
        "            df_lstm = pd.concat([date_df, df_lstm], axis=1)\n",
        "            df_lstm = df_lstm.set_index('Date')\n",
        "            df_lstm.index.name = 'Tarih'\n",
        "            st.write(df_lstm)\n",
        "\n",
        "\n",
        "        if cboxBILSTM :\n",
        "          with st.spinner('BILSTM modeli eğitiliyor...'):\n",
        "            X_train_bilstm, y_train_bilstm = prepare_data(dataset_train)\n",
        "            # Initialising the RNN\n",
        "            regressorBILSTM = Sequential()\n",
        "\n",
        "            # Adding the first Bidirectional LSTM layer and some Dropout regularisation\n",
        "            regressorBILSTM.add(Bidirectional(LSTM(units=50, return_sequences=True), input_shape=(X_train_bilstm.shape[1], 1)))\n",
        "            regressorBILSTM.add(Dropout(0.2))\n",
        "\n",
        "            # Adding a second Bidirectional LSTM layer and some Dropout regularisation\n",
        "            regressorBILSTM.add(Bidirectional(LSTM(units=50, return_sequences=True)))\n",
        "            regressorBILSTM.add(Dropout(0.2))\n",
        "\n",
        "            # Adding a third Bidirectional LSTM layer and some Dropout regularisation\n",
        "            regressorBILSTM.add(Bidirectional(LSTM(units=50, return_sequences=True)))\n",
        "            regressorBILSTM.add(Dropout(0.2))\n",
        "\n",
        "            # Adding a fourth Bidirectional LSTM layer and some Dropout regularisation\n",
        "            regressorBILSTM.add(Bidirectional(LSTM(units=50)))\n",
        "            regressorBILSTM.add(Dropout(0.2))\n",
        "\n",
        "            # Adding the output layer\n",
        "            regressorBILSTM.add(Dense(units=1))\n",
        "\n",
        "            # Compiling the RNN\n",
        "            regressorBILSTM.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "            # Fitting the RNN to the Training set\n",
        "            history = regressorBILSTM.fit(X_train_bilstm, y_train_bilstm, epochs=epoch, batch_size=32)\n",
        "\n",
        "            dataset_test = test_data\n",
        "            real_stock_price = dataset_test.iloc[:, 4:5].values\n",
        "\n",
        "            # Part 3 - Making the predictions and visualising the results\n",
        "            dataset_total = pd.concat((dataset_train['Close'], dataset_test['Close']), axis=0)\n",
        "            inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
        "            inputs = inputs.reshape(-1, 1)\n",
        "            inputs = sc.transform(inputs)\n",
        "            X_test = []\n",
        "            for i in range(60, len(inputs)):\n",
        "                X_test.append(inputs[i-60:i, 0])\n",
        "            X_test = np.array(X_test)\n",
        "            X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "            predicted_stock_price_bilstm = regressorBILSTM.predict(X_test)\n",
        "            predicted_stock_price_bilstm = sc.inverse_transform(predicted_stock_price_bilstm)\n",
        "\n",
        "            st.header('BILSTM Sonuçları')\n",
        "            plt.clf()\n",
        "            plt.plot(real_stock_price, color='red', label='Gerçek '+ ticker_symbol +' Kapanış Fiyatları')\n",
        "            plt.plot(predicted_stock_price_bilstm, color='blue', label='Tahmin Edilen '+ ticker_symbol +' Kapanış Fiyatları')\n",
        "            plt.title('BILSTM Model Tahminleri')\n",
        "            plt.xlabel('Zaman')\n",
        "            plt.ylabel('Kapanış Fiyatı')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "            st.pyplot(plt)\n",
        "            df_bilstm = pd.DataFrame(predicted_stock_price_bilstm, columns=['Tahmin Edilen BiLSTM Sonuçları'])\n",
        "            bilstm_predictions = predicted_stock_price_bilstm.flatten()\n",
        "            st.header('Tahmin Edilen ' + ticker_symbol + ' Hissesi Fiyatları BILSTM - Tablo')\n",
        "            df_bilstm = pd.concat([date_df, df_bilstm], axis=1)\n",
        "            df_bilstm = df_bilstm.set_index('Date')\n",
        "            df_bilstm.index.name = 'Tarih'\n",
        "            st.write(df_lstm)\n",
        "\n",
        "        if cboxCNN :\n",
        "          with st.spinner('CNN modeli eğitiliyor...'):\n",
        "            X_train_cnn, y_train_cnn = prepare_data(dataset_train)\n",
        "            # CNN modelini oluşturalım\n",
        "            modelCNN = Sequential()\n",
        "\n",
        "            # Birinci evrişim katmanını ekleyelim\n",
        "            modelCNN.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(60, 1)))\n",
        "\n",
        "            # Birinci havuzlama katmanını ekleyelim\n",
        "            modelCNN.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "            # İkinci evrişim katmanını ekleyelim\n",
        "            modelCNN.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "\n",
        "            # İkinci havuzlama katmanını ekleyelim\n",
        "            modelCNN.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "            # Düzleştirme katmanını ekleyelim\n",
        "            modelCNN.add(Flatten())\n",
        "\n",
        "            # Tam bağlı (fully connected) katmanı ekleyelim\n",
        "            modelCNN.add(Dense(units=50, activation='relu'))\n",
        "\n",
        "            # Çıkış katmanını ekleyelim\n",
        "            modelCNN.add(Dense(units=1))\n",
        "\n",
        "            # ModelCNNi derleyelim\n",
        "            modelCNN.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "            # ModelCNNi eğitelim\n",
        "            modelCNN.fit(X_train_cnn, y_train_cnn, epochs=epoch, batch_size=32)\n",
        "\n",
        "            # Test verisi üzerinde tahminlerde bulunalım\n",
        "            dataset_test = test_data\n",
        "            real_stock_price = dataset_test.iloc[:, 4:5].values\n",
        "            dataset_total = pd.concat((dataset_train['Close'], dataset_test['Close']), axis=0)\n",
        "            inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
        "            inputs = inputs.reshape(-1, 1)\n",
        "            inputs = sc.transform(inputs)\n",
        "            X_test = []\n",
        "            for i in range(60, len(inputs)):\n",
        "                X_test.append(inputs[i-60:i, 0])\n",
        "            X_test = np.array(X_test)\n",
        "            X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "            predicted_stock_price_cnn = modelCNN.predict(X_test)\n",
        "            predicted_stock_price_cnn = sc.inverse_transform(predicted_stock_price_cnn)\n",
        "\n",
        "            # Sonuçları görselleştirelim\n",
        "            st.header('CNN Sonuçları')\n",
        "            plt.clf()\n",
        "            plt.plot(real_stock_price, color='red',label='Gerçek '+ ticker_symbol +' Kapanış Fiyatları')\n",
        "            plt.plot(predicted_stock_price_cnn, color='blue', label='Tahmin Edilen '+ ticker_symbol +' Kapanış Fiyatları')\n",
        "            plt.title('CNN Model Tahminleri')\n",
        "            plt.xlabel('Zaman')\n",
        "            plt.ylabel('Kapanış Fiyatı')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "            st.pyplot(plt)\n",
        "            df_cnn = pd.DataFrame(predicted_stock_price_cnn, columns=['Tahmin Edilen CNN Sonuçları'])\n",
        "            cnn_predictions = predicted_stock_price_cnn.flatten()\n",
        "            st.header('Tahmin Edilen ' + ticker_symbol + ' Hissesi Fiyatları CNN - Tablo')\n",
        "            df_cnn = pd.concat([date_df, df_cnn], axis=1)\n",
        "            df_cnn = df_cnn.set_index('Date')\n",
        "            df_cnn.index.name = 'Tarih'\n",
        "            st.write(df_cnn)\n",
        "\n",
        "        if cboxRNN :\n",
        "          with st.spinner('RNN modeli eğitiliyor...'):\n",
        "            X_train_rnn, y_train_rnn = prepare_data(dataset_train)\n",
        "\n",
        "            # RNN modelini oluşturalım\n",
        "            modelRNN = Sequential()\n",
        "\n",
        "            # RNN katmanını ekleyelim\n",
        "            modelRNN.add(SimpleRNN(units=50, input_shape=(60, 1)))\n",
        "            modelRNN.add(Dropout(0.2))\n",
        "\n",
        "            # Tam bağlı (fully connected) katmanı ekleyelim\n",
        "            modelRNN.add(Dense(units=1))\n",
        "            modelRNN.add(Dropout(0.2))\n",
        "\n",
        "            # modelRNNi derleyelim\n",
        "            modelRNN.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "            # modelRNNi eğitelim\n",
        "            modelRNN.fit(X_train_rnn, y_train_rnn, epochs=epoch, batch_size=32)\n",
        "\n",
        "            # Test verisi üzerinde tahminlerde bulunalım\n",
        "            dataset_test = test_data\n",
        "            real_stock_price = dataset_test.iloc[:, 4:5].values\n",
        "\n",
        "            dataset_total = pd.concat((dataset_train['Close'], dataset_test['Close']), axis=0)\n",
        "            inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
        "            inputs = inputs.reshape(-1, 1)\n",
        "            inputs = sc.transform(inputs)\n",
        "            X_test = []\n",
        "\n",
        "            for i in range(60, len(inputs)):\n",
        "                X_test.append(inputs[i-60:i, 0])\n",
        "            X_test = np.array(X_test)\n",
        "            X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "            predicted_stock_price_rnn = modelRNN.predict(X_test)\n",
        "            predicted_stock_price_rnn = sc.inverse_transform(predicted_stock_price_rnn)\n",
        "\n",
        "            # Sonuçları görselleştirelim\n",
        "            st.header('RNN Sonuçları')\n",
        "            plt.clf()\n",
        "            plt.plot(real_stock_price, color='red', label='Gerçek '+ ticker_symbol +' Kapanış Fiyatları')\n",
        "            plt.plot(predicted_stock_price_rnn, color='blue', label='Tahmin Edilen '+ ticker_symbol +' Kapanış Fiyatları')\n",
        "            plt.title('RNN Model Tahminleri')\n",
        "            plt.xlabel('Zaman')\n",
        "            plt.ylabel('Kapanış Fiyatı')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "            st.pyplot(plt)\n",
        "            df_rnn = pd.DataFrame(predicted_stock_price_rnn, columns=['Tahmin Edilen RNN Sonuçları'])\n",
        "            rnn_predictions = predicted_stock_price_rnn.flatten()\n",
        "            st.header('Tahmin Edilen ' + ticker_symbol + ' Hissesi Fiyatları RNN - Tablo')\n",
        "            df_rnn = pd.concat([date_df, df_rnn], axis=1)\n",
        "            df_rnn = df_rnn.set_index('Date')\n",
        "            df_rnn.index.name = 'Tarih'\n",
        "            st.write(df_rnn)\n",
        "\n",
        "        if cboxGRU :\n",
        "          with st.spinner('GRU modeli eğitiliyor...'):\n",
        "            X_train_gru, y_train_gru = prepare_data(dataset_train)\n",
        "\n",
        "             # Getting the real stock price of 2017\n",
        "            dataset_test = test_data\n",
        "            real_stock_price = dataset_test.iloc[:, 4:5].values\n",
        "\n",
        "            # Getting the predicted stock price of 2017\n",
        "            dataset_total = pd.concat((dataset_train['Close'], dataset_test['Close']), axis=0)\n",
        "            inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
        "            inputs = inputs.reshape(-1, 1)\n",
        "            inputs = sc.transform(inputs)\n",
        "\n",
        "            X_test = []\n",
        "            for i in range(60, len(inputs)):\n",
        "                X_test.append(inputs[i-60:i, 0])\n",
        "            X_test = np.array(X_test)\n",
        "            X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "\n",
        "            regressorGRU = Sequential()\n",
        "            # First GRU layer with Dropout regularisation\n",
        "            regressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train_gru.shape[1],1), activation='tanh'))\n",
        "            regressorGRU.add(Dropout(0.2))\n",
        "            # Second GRU layer\n",
        "            regressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train_gru.shape[1],1), activation='tanh'))\n",
        "            regressorGRU.add(Dropout(0.2))\n",
        "            # Third GRU layer\n",
        "            regressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train_gru.shape[1],1), activation='tanh'))\n",
        "            regressorGRU.add(Dropout(0.2))\n",
        "            # Fourth GRU layer\n",
        "            regressorGRU.add(GRU(units=50, activation='tanh'))\n",
        "            regressorGRU.add(Dropout(0.2))\n",
        "            # The output layer\n",
        "            regressorGRU.add(Dense(units=1))\n",
        "\n",
        "            regressorGRU.compile(optimizer=SGD(learning_rate=0.01, momentum=0.9, nesterov=False), loss='mean_squared_error')\n",
        "\n",
        "            # fitting the model\n",
        "\n",
        "            regressorGRU.fit(X_train_gru, y_train_gru, epochs=epoch, batch_size=150)\n",
        "\n",
        "            predicted_stock_price_gru = regressorGRU.predict(X_test)\n",
        "            predicted_stock_price_gru = sc.inverse_transform(predicted_stock_price_gru)\n",
        "\n",
        "            st.header('GRU Sonuçları')\n",
        "            plt.clf()\n",
        "            plt.plot(real_stock_price, color='red', label='Gerçek '+ ticker_symbol +' Kapanış Fiyatları')\n",
        "            plt.plot(predicted_stock_price_gru, color='blue', label='Tahmin Edilen '+ ticker_symbol +' Kapanış Fiyatları')\n",
        "            plt.title('GRU Model Tahminleri')\n",
        "            plt.xlabel('Zaman')\n",
        "            plt.ylabel('Kapanış Fiyatı')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "            st.pyplot(plt)\n",
        "            df_gru = pd.DataFrame(predicted_stock_price_gru, columns=['Tahmin Edilen GRU Sonuçları'])\n",
        "            gru_predictions = predicted_stock_price_gru.flatten()\n",
        "            st.header('Tahmin Edilen ' + ticker_symbol + ' Hissesi Fiyatları GRU - Tablo')\n",
        "            df_gru = pd.concat([date_df, df_gru], axis=1)\n",
        "            df_gru = df_gru.set_index('Date')\n",
        "            df_gru.index.name = 'Tarih'\n",
        "            st.write(df_gru)\n",
        "\n",
        "        if cboxXGB:\n",
        "           with st.spinner('XGBoost modeli eğitiliyor...'):\n",
        "\n",
        "              X_train_xgb = []\n",
        "              y_train_xgb = dataset_train['Close'].values[60:]\n",
        "              for i in range(60, len(dataset_train)):\n",
        "                  features = []\n",
        "                  # Özellik 1: Kapanış fiyatları\n",
        "                  features.append(dataset_train['Close'].values[i-1])\n",
        "                  # Özellik 2: Hacim\n",
        "                  features.append(dataset_train['Volume'].values[i-1])\n",
        "                  # Özellik 3: 5 günlük hareketli ortalama\n",
        "                  features.append(dataset_train['Close'].rolling(window=5).mean().values[i-1])\n",
        "                  # Özellik 4: 30 günlük hareketli ortalama\n",
        "                  features.append(dataset_train['Close'].rolling(window=30).mean().values[i-1])\n",
        "                  # Özellik 5: 365 günlük hareketli ortalama\n",
        "                  features.append(dataset_train['Close'].rolling(window=365).mean().values[i-1])\n",
        "                  X_train_xgb.append(features)\n",
        "              X_train_xgb = np.array(X_train_xgb)\n",
        "\n",
        "              # XGBoost veri yapısına dönüştürme\n",
        "              dtrain = xgb.DMatrix(X_train_xgb, label=y_train_xgb)\n",
        "\n",
        "              # XGBoost parametre ayarları\n",
        "              param_grid = {\n",
        "                  'max_depth': [3, 6, 9],\n",
        "                  'learning_rate': [0.01, 0.1, 0.3],\n",
        "                  'n_estimators': [100, 200, 300]\n",
        "              }\n",
        "\n",
        "              # Modeli oluşturma\n",
        "              xgb_model = xgb.XGBRegressor()\n",
        "              grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "              grid_search.fit(X_train_xgb, y_train_xgb)\n",
        "\n",
        "              # En iyi parametreleri bulma\n",
        "              best_params = grid_search.best_params_\n",
        "\n",
        "              # Final modelini oluşturma\n",
        "              final_xgb_model = xgb.XGBRegressor(**best_params)\n",
        "              final_xgb_model.fit(X_train_xgb, y_train_xgb)\n",
        "\n",
        "              # Test veri seti için tahminler yapma\n",
        "              X_test_xgb = []\n",
        "              for i in range(len(dataset_train), len(dataset_train) + len(test_data)):\n",
        "                  features = []\n",
        "                  features.append(stock_data['Close'].values[i-1])\n",
        "                  features.append(stock_data['Volume'].values[i-1])\n",
        "                  features.append(stock_data['Close'].rolling(window=5).mean().values[i-1])\n",
        "                  features.append(stock_data['Close'].rolling(window=30).mean().values[i-1])\n",
        "                  features.append(stock_data['Close'].rolling(window=365).mean().values[i-1])\n",
        "                  X_test_xgb.append(features)\n",
        "              X_test_xgb = np.array(X_test_xgb)\n",
        "\n",
        "              predicted_stock_price_xgb = final_xgb_model.predict(X_test_xgb)\n",
        "              real_stock_price = test_data.iloc[:, 4:5].values\n",
        "\n",
        "              st.header('XGBoost Sonuçları')\n",
        "              plt.clf()\n",
        "              plt.plot(real_stock_price, color='red', label='Gerçek '+ ticker_symbol +' Kapanış Fiyatları')\n",
        "              plt.plot(predicted_stock_price_xgb, color='blue', label='Tahmin Edilen '+ ticker_symbol +' Kapanış Fiyatları (XGBoost)')\n",
        "              plt.title(ticker_symbol + ' Borsa Değeri Tahmini (XGBoost)')\n",
        "              plt.xlabel('Zaman')\n",
        "              plt.ylabel('Kapanış Fiyatı')\n",
        "              plt.legend()\n",
        "              plt.show()\n",
        "              st.pyplot(plt)\n",
        "              df_xgb = pd.DataFrame(predicted_stock_price_xgb, columns=['Tahmin Edilen XGBoost Sonuçları'])\n",
        "              xgb_predictions = predicted_stock_price_xgb.flatten()\n",
        "              st.header('Tahmin Edilen ' + ticker_symbol + ' Hissesi Fiyatları XGBoost - Tablo')\n",
        "              df_xgb = pd.concat([date_df, df_xgb], axis=1)\n",
        "              df_xgb = df_xgb.set_index('Date')\n",
        "              df_xgb.index.name = 'Tarih'\n",
        "              st.write(df_xgb)\n",
        "\n",
        "        all_predictions = []\n",
        "\n",
        "        if len(lstm_predictions) > 0:\n",
        "            all_predictions.append(lstm_predictions)\n",
        "\n",
        "        if len(bilstm_predictions) > 0:\n",
        "            all_predictions.append(bilstm_predictions)\n",
        "\n",
        "        # if len(arima_predictions) > 0:\n",
        "        #   all_predictions.append(arima_predictions)\n",
        "\n",
        "        if len(cnn_predictions) > 0:\n",
        "            all_predictions.append(cnn_predictions)\n",
        "\n",
        "        if len(rnn_predictions) > 0:\n",
        "            all_predictions.append(rnn_predictions)\n",
        "\n",
        "        if len(gru_predictions) > 0:\n",
        "            all_predictions.append(gru_predictions)\n",
        "\n",
        "        if len(xgb_predictions) > 0:\n",
        "            all_predictions.append(xgb_predictions)\n",
        "\n",
        "\n",
        "\n",
        "        if len(all_predictions) > 1:\n",
        "          stacked_predictions = np.mean(all_predictions, axis=0)\n",
        "          meta_model = LinearRegression()\n",
        "          meta_model.fit(np.array(all_predictions).T, real_stock_price)  # real_stock_price, tahmin edilen fiyatların gerçek değerleridir\n",
        "          stacked_predictions_test = meta_model.predict(np.array(all_predictions).T)\n",
        "          plt.clf()\n",
        "          st.header('STACKED ENSEMBLE Sonuçları')\n",
        "          plt.plot(real_stock_price, color='red', label='Gerçek Kapanış Fiyatları')\n",
        "          plt.plot(stacked_predictions_test, color='blue', label='Stacked Ensemble Tahminleri')\n",
        "          plt.title('Stacked Ensemble Tahminleri')\n",
        "          plt.xlabel('Zaman')\n",
        "          plt.ylabel('Kapanış Fiyatı')\n",
        "          plt.legend()\n",
        "          plt.show()\n",
        "          st.pyplot(plt)\n",
        "\n",
        "          df_SEnsemble = pd.DataFrame(stacked_predictions_test, columns=['Tahmin Edilen Stacked Ensemble Sonuçları'])\n",
        "          df_SEnsemble = pd.concat([date_df, df_SEnsemble], axis=1)\n",
        "          SEnsemble_predictions = stacked_predictions_test.flatten()\n",
        "          st.header('Tahmin Edilen ' + ticker_symbol + ' Hissesi Fiyatları Stacked Ensemble - Tablo')\n",
        "          df_SEnsemble = df_SEnsemble.set_index('Date')\n",
        "          df_SEnsemble.index.name = 'Tarih'\n",
        "          st.write(df_SEnsemble)\n",
        "          st.success('Model eğitimi tamamlandı!')\n",
        "\n",
        "\n",
        "          # Displaying predicted prices in a table\n",
        "\n",
        "\n",
        "          # # Tahmin sonuçlarını birleştirelim\n",
        "          # df_combined = all_predictions[0]\n",
        "          # for df in all_predictions[1:]:\n",
        "          #     df_combined = pd.merge(df_combined, df, on='Date')\n",
        "\n",
        "          # # 'Date' kolonunu indeks olarak ayarlayıp adını 'Tarih' olarak değiştirme\n",
        "          # df_combined = df_combined.set_index('Date')\n",
        "          # df_combined.index.name = 'Tarih'\n",
        "\n",
        "          # # Tahmin verilerini Streamlit ile yazdırma\n",
        "          # st.header('Tahmin Edilen Hisse Fiyatları')\n",
        "          # st.write(df_combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwHpyEekBM8w"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbO_KbBOBSD_",
        "outputId": "ef58b881-8a7a-403a-98de-70accbe746b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.197.120.119:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.274s\n",
            "your url is: https://brown-planes-sin.loca.lt\n",
            "2024-06-02 16:57:54.747678: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-02 16:57:54.747746: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-02 16:57:54.749535: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-02 16:57:54.760086: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-02 16:57:56.232955: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "Epoch 1/40\n",
            "14/14 [==============================] - 10s 168ms/step - loss: 0.1440\n",
            "Epoch 2/40\n",
            "14/14 [==============================] - 2s 140ms/step - loss: 0.0281\n",
            "Epoch 3/40\n",
            "14/14 [==============================] - 1s 100ms/step - loss: 0.0198\n",
            "Epoch 4/40\n",
            "14/14 [==============================] - 1s 99ms/step - loss: 0.0174\n",
            "Epoch 5/40\n",
            "14/14 [==============================] - 1s 100ms/step - loss: 0.0170\n",
            "Epoch 6/40\n",
            "14/14 [==============================] - 1s 98ms/step - loss: 0.0173\n",
            "Epoch 7/40\n",
            "14/14 [==============================] - 1s 100ms/step - loss: 0.0160\n",
            "Epoch 8/40\n",
            "14/14 [==============================] - 1s 101ms/step - loss: 0.0150\n",
            "Epoch 9/40\n",
            "14/14 [==============================] - 2s 125ms/step - loss: 0.0132\n",
            "Epoch 10/40\n",
            "14/14 [==============================] - 2s 171ms/step - loss: 0.0139\n",
            "Epoch 11/40\n",
            "14/14 [==============================] - 2s 143ms/step - loss: 0.0121\n",
            "Epoch 12/40\n",
            "14/14 [==============================] - 1s 99ms/step - loss: 0.0124\n",
            "Epoch 13/40\n",
            "14/14 [==============================] - 1s 100ms/step - loss: 0.0129\n",
            "Epoch 14/40\n",
            "14/14 [==============================] - 1s 99ms/step - loss: 0.0131\n",
            "Epoch 15/40\n",
            "14/14 [==============================] - 1s 100ms/step - loss: 0.0130\n",
            "Epoch 16/40\n",
            "14/14 [==============================] - 1s 102ms/step - loss: 0.0123\n",
            "Epoch 17/40\n",
            "14/14 [==============================] - 1s 102ms/step - loss: 0.0112\n",
            "Epoch 18/40\n",
            "14/14 [==============================] - 2s 121ms/step - loss: 0.0107\n",
            "Epoch 19/40\n",
            "14/14 [==============================] - 2s 163ms/step - loss: 0.0122\n",
            "Epoch 20/40\n",
            "14/14 [==============================] - 2s 144ms/step - loss: 0.0111\n",
            "Epoch 21/40\n",
            "14/14 [==============================] - 1s 107ms/step - loss: 0.0117\n",
            "Epoch 22/40\n",
            "14/14 [==============================] - 1s 98ms/step - loss: 0.0126\n",
            "Epoch 23/40\n",
            "14/14 [==============================] - 1s 98ms/step - loss: 0.0123\n",
            "Epoch 24/40\n",
            "14/14 [==============================] - 1s 98ms/step - loss: 0.0113\n",
            "Epoch 25/40\n",
            "14/14 [==============================] - 1s 100ms/step - loss: 0.0113\n",
            "Epoch 26/40\n",
            "14/14 [==============================] - 1s 101ms/step - loss: 0.0095\n",
            "Epoch 27/40\n",
            "14/14 [==============================] - 2s 147ms/step - loss: 0.0097\n",
            "Epoch 28/40\n",
            "14/14 [==============================] - 2s 174ms/step - loss: 0.0093\n",
            "Epoch 29/40\n",
            "14/14 [==============================] - 2s 116ms/step - loss: 0.0102\n",
            "Epoch 30/40\n",
            "14/14 [==============================] - 1s 99ms/step - loss: 0.0105\n",
            "Epoch 31/40\n",
            "14/14 [==============================] - 1s 100ms/step - loss: 0.0096\n",
            "Epoch 32/40\n",
            "14/14 [==============================] - 1s 99ms/step - loss: 0.0105\n",
            "Epoch 33/40\n",
            "14/14 [==============================] - 1s 101ms/step - loss: 0.0096\n",
            "Epoch 34/40\n",
            "14/14 [==============================] - 1s 102ms/step - loss: 0.0107\n",
            "Epoch 35/40\n",
            "14/14 [==============================] - 1s 106ms/step - loss: 0.0100\n",
            "Epoch 36/40\n",
            "14/14 [==============================] - 2s 154ms/step - loss: 0.0095\n",
            "Epoch 37/40\n",
            "14/14 [==============================] - 2s 165ms/step - loss: 0.0098\n",
            "Epoch 38/40\n",
            "14/14 [==============================] - 2s 119ms/step - loss: 0.0089\n",
            "Epoch 39/40\n",
            "14/14 [==============================] - 1s 107ms/step - loss: 0.0093\n",
            "Epoch 40/40\n",
            "14/14 [==============================] - 1s 102ms/step - loss: 0.0089\n",
            "16/16 [==============================] - 2s 28ms/step\n",
            "Epoch 1/40\n",
            "14/14 [==============================] - 20s 193ms/step - loss: 0.0965\n",
            "Epoch 2/40\n",
            "14/14 [==============================] - 3s 190ms/step - loss: 0.0203\n",
            "Epoch 3/40\n",
            "14/14 [==============================] - 3s 189ms/step - loss: 0.0154\n",
            "Epoch 4/40\n",
            "14/14 [==============================] - 5s 345ms/step - loss: 0.0133\n",
            "Epoch 5/40\n",
            "14/14 [==============================] - 3s 194ms/step - loss: 0.0117\n",
            "Epoch 6/40\n",
            "14/14 [==============================] - 3s 199ms/step - loss: 0.0091\n",
            "Epoch 7/40\n",
            "14/14 [==============================] - 3s 190ms/step - loss: 0.0089\n",
            "Epoch 8/40\n",
            "14/14 [==============================] - 3s 247ms/step - loss: 0.0086\n",
            "Epoch 9/40\n",
            "14/14 [==============================] - 5s 325ms/step - loss: 0.0077\n",
            "Epoch 10/40\n",
            "14/14 [==============================] - 3s 207ms/step - loss: 0.0080\n",
            "Epoch 11/40\n",
            "14/14 [==============================] - 3s 189ms/step - loss: 0.0076\n",
            "Epoch 12/40\n",
            "14/14 [==============================] - 3s 189ms/step - loss: 0.0070\n",
            "Epoch 13/40\n",
            "14/14 [==============================] - 4s 320ms/step - loss: 0.0075\n",
            "Epoch 14/40\n",
            "14/14 [==============================] - 3s 217ms/step - loss: 0.0088\n",
            "Epoch 15/40\n",
            "14/14 [==============================] - 3s 186ms/step - loss: 0.0075\n",
            "Epoch 16/40\n",
            "14/14 [==============================] - 3s 185ms/step - loss: 0.0070\n",
            "Epoch 17/40\n",
            "14/14 [==============================] - 3s 189ms/step - loss: 0.0066\n",
            "Epoch 18/40\n",
            "14/14 [==============================] - 5s 345ms/step - loss: 0.0063\n",
            "Epoch 19/40\n",
            "14/14 [==============================] - 3s 206ms/step - loss: 0.0071\n",
            "Epoch 20/40\n",
            "14/14 [==============================] - 3s 215ms/step - loss: 0.0065\n",
            "Epoch 21/40\n",
            "14/14 [==============================] - 3s 209ms/step - loss: 0.0058\n",
            "Epoch 22/40\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0074\n",
            "Epoch 23/40\n",
            "14/14 [==============================] - 4s 251ms/step - loss: 0.0058\n",
            "Epoch 24/40\n",
            "14/14 [==============================] - 3s 196ms/step - loss: 0.0058\n",
            "Epoch 25/40\n",
            "14/14 [==============================] - 3s 188ms/step - loss: 0.0057\n",
            "Epoch 26/40\n",
            "14/14 [==============================] - 3s 203ms/step - loss: 0.0062\n",
            "Epoch 27/40\n",
            "14/14 [==============================] - 5s 350ms/step - loss: 0.0055\n",
            "Epoch 28/40\n",
            "14/14 [==============================] - 3s 192ms/step - loss: 0.0061\n",
            "Epoch 29/40\n",
            "14/14 [==============================] - 3s 196ms/step - loss: 0.0060\n",
            "Epoch 30/40\n",
            "14/14 [==============================] - 3s 192ms/step - loss: 0.0052\n",
            "Epoch 31/40\n",
            "14/14 [==============================] - 3s 247ms/step - loss: 0.0055\n",
            "Epoch 32/40\n",
            "14/14 [==============================] - 4s 290ms/step - loss: 0.0052\n",
            "Epoch 33/40\n",
            "14/14 [==============================] - 3s 189ms/step - loss: 0.0051\n",
            "Epoch 34/40\n",
            "14/14 [==============================] - 3s 196ms/step - loss: 0.0057\n",
            "Epoch 35/40\n",
            "14/14 [==============================] - 3s 187ms/step - loss: 0.0059\n",
            "Epoch 36/40\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0057\n",
            "Epoch 37/40\n",
            "14/14 [==============================] - 3s 227ms/step - loss: 0.0048\n",
            "Epoch 38/40\n",
            "14/14 [==============================] - 3s 199ms/step - loss: 0.0050\n",
            "Epoch 39/40\n",
            "14/14 [==============================] - 3s 192ms/step - loss: 0.0055\n",
            "Epoch 40/40\n",
            "14/14 [==============================] - 3s 191ms/step - loss: 0.0058\n",
            "16/16 [==============================] - 4s 48ms/step\n",
            "Epoch 1/40\n",
            "14/14 [==============================] - 1s 5ms/step - loss: 0.1238\n",
            "Epoch 2/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0239\n",
            "Epoch 3/40\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0192\n",
            "Epoch 4/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0188\n",
            "Epoch 5/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0165\n",
            "Epoch 6/40\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0150\n",
            "Epoch 7/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0138\n",
            "Epoch 8/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0129\n",
            "Epoch 9/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0118\n",
            "Epoch 10/40\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0107\n",
            "Epoch 11/40\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0099\n",
            "Epoch 12/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0092\n",
            "Epoch 13/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0088\n",
            "Epoch 14/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0083\n",
            "Epoch 15/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0080\n",
            "Epoch 16/40\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0074\n",
            "Epoch 17/40\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0073\n",
            "Epoch 18/40\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0073\n",
            "Epoch 19/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0069\n",
            "Epoch 20/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0067\n",
            "Epoch 21/40\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0065\n",
            "Epoch 22/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0067\n",
            "Epoch 23/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0065\n",
            "Epoch 24/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0064\n",
            "Epoch 25/40\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0070\n",
            "Epoch 26/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0077\n",
            "Epoch 27/40\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0071\n",
            "Epoch 28/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0062\n",
            "Epoch 29/40\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0055\n",
            "Epoch 30/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0056\n",
            "Epoch 31/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0053\n",
            "Epoch 32/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0052\n",
            "Epoch 33/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0053\n",
            "Epoch 34/40\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0055\n",
            "Epoch 35/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0050\n",
            "Epoch 36/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0052\n",
            "Epoch 37/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0054\n",
            "Epoch 38/40\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0047\n",
            "Epoch 39/40\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0047\n",
            "Epoch 40/40\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0050\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "Epoch 1/40\n",
            "14/14 [==============================] - 2s 18ms/step - loss: 0.4016\n",
            "Epoch 2/40\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1542\n",
            "Epoch 3/40\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.1275\n",
            "Epoch 4/40\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1110\n",
            "Epoch 5/40\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0910\n",
            "Epoch 6/40\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0985\n",
            "Epoch 7/40\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1136\n",
            "Epoch 8/40\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1110\n",
            "Epoch 9/40\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1032\n",
            "Epoch 10/40\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1125\n",
            "Epoch 11/40\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1128\n",
            "Epoch 12/40\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1090\n",
            "Epoch 13/40\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1138\n",
            "Epoch 14/40\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1154\n",
            "Epoch 15/40\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1133\n",
            "Epoch 16/40\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0920\n",
            "Epoch 17/40\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0998\n",
            "Epoch 18/40\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0891\n",
            "Epoch 19/40\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0987\n",
            "Epoch 20/40\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0852\n",
            "Epoch 21/40\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0923\n",
            "Epoch 22/40\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0894\n",
            "Epoch 23/40\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0975\n",
            "Epoch 24/40\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0890\n",
            "Epoch 25/40\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0968\n",
            "Epoch 26/40\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0989\n",
            "Epoch 27/40\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1085\n",
            "Epoch 28/40\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0999\n",
            "Epoch 29/40\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.1016\n",
            "Epoch 30/40\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1046\n",
            "Epoch 31/40\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0992\n",
            "Epoch 32/40\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.1084\n",
            "Epoch 33/40\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0943\n",
            "Epoch 34/40\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0999\n",
            "Epoch 35/40\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1028\n",
            "Epoch 36/40\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0964\n",
            "Epoch 37/40\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0825\n",
            "Epoch 38/40\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0955\n",
            "Epoch 39/40\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0952\n",
            "Epoch 40/40\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0890\n",
            "16/16 [==============================] - 0s 5ms/step\n",
            "Epoch 1/40\n",
            "3/3 [==============================] - 9s 202ms/step - loss: 0.3161\n",
            "Epoch 2/40\n",
            "3/3 [==============================] - 1s 204ms/step - loss: 0.0564\n",
            "Epoch 3/40\n",
            "3/3 [==============================] - 1s 197ms/step - loss: 0.1689\n",
            "Epoch 4/40\n",
            "3/3 [==============================] - 1s 211ms/step - loss: 0.0694\n",
            "Epoch 5/40\n",
            "3/3 [==============================] - 1s 196ms/step - loss: 0.0433\n",
            "Epoch 6/40\n",
            "3/3 [==============================] - 1s 195ms/step - loss: 0.0770\n",
            "Epoch 7/40\n",
            "3/3 [==============================] - 1s 195ms/step - loss: 0.0454\n",
            "Epoch 8/40\n",
            "3/3 [==============================] - 1s 194ms/step - loss: 0.0280\n",
            "Epoch 9/40\n",
            "3/3 [==============================] - 1s 204ms/step - loss: 0.0411\n",
            "Epoch 10/40\n",
            "3/3 [==============================] - 1s 219ms/step - loss: 0.0351\n",
            "Epoch 11/40\n",
            "3/3 [==============================] - 1s 223ms/step - loss: 0.0243\n",
            "Epoch 12/40\n",
            "3/3 [==============================] - 1s 199ms/step - loss: 0.0276\n",
            "Epoch 13/40\n",
            "3/3 [==============================] - 1s 193ms/step - loss: 0.0286\n",
            "Epoch 14/40\n",
            "3/3 [==============================] - 1s 363ms/step - loss: 0.0227\n",
            "Epoch 15/40\n",
            "3/3 [==============================] - 1s 374ms/step - loss: 0.0239\n",
            "Epoch 16/40\n",
            "3/3 [==============================] - 1s 373ms/step - loss: 0.0243\n",
            "Epoch 17/40\n",
            "3/3 [==============================] - 1s 401ms/step - loss: 0.0224\n",
            "Epoch 18/40\n",
            "3/3 [==============================] - 1s 210ms/step - loss: 0.0202\n",
            "Epoch 19/40\n",
            "3/3 [==============================] - 1s 196ms/step - loss: 0.0214\n",
            "Epoch 20/40\n",
            "3/3 [==============================] - 1s 196ms/step - loss: 0.0207\n",
            "Epoch 21/40\n",
            "3/3 [==============================] - 1s 203ms/step - loss: 0.0203\n",
            "Epoch 22/40\n",
            "3/3 [==============================] - 1s 197ms/step - loss: 0.0194\n",
            "Epoch 23/40\n",
            "3/3 [==============================] - 1s 199ms/step - loss: 0.0187\n",
            "Epoch 24/40\n",
            "3/3 [==============================] - 1s 195ms/step - loss: 0.0188\n",
            "Epoch 25/40\n",
            "3/3 [==============================] - 1s 194ms/step - loss: 0.0178\n",
            "Epoch 26/40\n",
            "3/3 [==============================] - 1s 204ms/step - loss: 0.0171\n",
            "Epoch 27/40\n",
            "3/3 [==============================] - 1s 202ms/step - loss: 0.0171\n",
            "Epoch 28/40\n",
            "3/3 [==============================] - 1s 204ms/step - loss: 0.0157\n",
            "Epoch 29/40\n",
            "3/3 [==============================] - 1s 204ms/step - loss: 0.0171\n",
            "Epoch 30/40\n",
            "3/3 [==============================] - 1s 196ms/step - loss: 0.0157\n",
            "Epoch 31/40\n",
            "3/3 [==============================] - 1s 203ms/step - loss: 0.0156\n",
            "Epoch 32/40\n",
            "3/3 [==============================] - 1s 198ms/step - loss: 0.0141\n",
            "Epoch 33/40\n",
            "3/3 [==============================] - 1s 201ms/step - loss: 0.0131\n",
            "Epoch 34/40\n",
            "3/3 [==============================] - 1s 298ms/step - loss: 0.0137\n",
            "Epoch 35/40\n",
            "3/3 [==============================] - 1s 363ms/step - loss: 0.0129\n",
            "Epoch 36/40\n",
            "3/3 [==============================] - 1s 385ms/step - loss: 0.0118\n",
            "Epoch 37/40\n",
            "3/3 [==============================] - 1s 353ms/step - loss: 0.0113\n",
            "Epoch 38/40\n",
            "3/3 [==============================] - 1s 297ms/step - loss: 0.0108\n",
            "Epoch 39/40\n",
            "3/3 [==============================] - 1s 200ms/step - loss: 0.0113\n",
            "Epoch 40/40\n",
            "3/3 [==============================] - 1s 200ms/step - loss: 0.0106\n",
            "16/16 [==============================] - 2s 24ms/step\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}